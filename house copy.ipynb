{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from doodleLoaderSimple import DoodleDatasetSimple\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation for the house image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0) (1, 1) (2, 2) (3, 0) (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Number to class labels mapping\n",
    "class_dict = {\n",
    "    0: 'stress',\n",
    "    1: 'introvert',\n",
    "    2: 'extrovert'\n",
    "}\n",
    "\n",
    "# Loading the data from the .csv file\n",
    "# First row is a header\n",
    "data = np.genfromtxt(r'D:\\COLLEGE_STUDIES\\SEM-6\\ML_NLP_project\\data\\houseData.csv', dtype=int, delimiter=',', names=True)\n",
    "\n",
    "print(data[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization: Plot the distribution of classes\n",
    "# def plot_class_distribution(translation_dict):\n",
    "#     \"\"\"\n",
    "#     Plots the distribution of class labels in the dataset.\n",
    "    \n",
    "#     :param translation_dict: Dictionary mapping image filenames to class labels.\n",
    "#     \"\"\"\n",
    "#     class_counts = np.bincount(list(translation_dict.values()))  # Count occurrences of each class\n",
    "#     class_labels = [class_dict[i] for i in range(len(class_counts))]  # Get class names\n",
    "    \n",
    "#     plt.figure(figsize=(4, 3))\n",
    "#     plt.bar(class_labels, class_counts, color=['red', 'blue', 'green'])\n",
    "#     plt.xlabel(\"Class Labels\")\n",
    "#     plt.ylabel(\"Number of Images\")\n",
    "#     plt.title(\"Class Distribution in Dataset\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Call the function to visualize the dataset distribution\n",
    "# plot_class_distribution(translation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(dictClass, arr):\n",
    "    \"\"\"\n",
    "    Redundant method that counts the occurrences of each class in the dataset\n",
    "    Can be used to create weights if the class distribution is unbalanced\n",
    "    :param dictClass: Dictionary that maps number to class labels\n",
    "    :param arr: The array that contains the data\n",
    "    :return: The number of occurrences for each class in the given array\n",
    "    \"\"\"\n",
    "    unique, count = numpy.unique(arr, return_counts=True)\n",
    "    print(dict(zip(dictClass.values(), count)))\n",
    "    count = 1 / count\n",
    "    count = count / sum(count)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the image IDs to the ID values in the .csv file.\n",
    "translation_dict = dict( zip([f'{id}.png' for id in data['id']], data['class']))\n",
    "\n",
    "# Prepare each image to be passed as a Tensor product to the model.\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Prepare the data by matching it to its label and transforming it to a Tensor product.\n",
    "housedata = DoodleDatasetSimple(r'D:\\\\COLLEGE_STUDIES\\\\SEM-6\\\\ML_NLP_project\\\\images\\\\house\\\\', data_transforms, translation_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% of the data for training.\n",
    "train_len = int(housedata.__len__() * 0.7)\n",
    "# 20% of the data for validation.\n",
    "test_len = int(housedata.__len__() * 0.3 + 1)\n",
    "# Split the data at a random point.\n",
    "train_set, val_set = torch.utils.data.random_split(housedata, [train_len, test_len])\n",
    "# Shuffle and load the labeled images in batches of 4 for training.\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, num_workers=0, drop_last=True)\n",
    "# Load the labeled images in batches of 4 for validation after training the model.\n",
    "test_loader = DataLoader(val_set, batch_size=4, shuffle=False, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MultilabelClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom CNN model to replace ResNet-34.\n",
    "    It extracts hierarchical features and replaces the last layer with a classification head.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features):\n",
    "        super(MultilabelClassifier, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # First Convolution Block\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Second Convolution Block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Third Convolution Block\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Fourth Convolution Block\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Adaptive Pooling to match ResNet output size\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        # Fully Connected Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, n_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten for FC layer\n",
    "        return {'class': self.classifier(x)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to use as the GPU if there is compatible hardware\n",
    "# Otherwise run the model on the cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultilabelClassifier(3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, pictures):\n",
    "    \"\"\"\n",
    "    Method used by the model as the criterion for training.\n",
    "    Cross entropy loss used as the loss function\n",
    "    :param outputs: Predicted labels by the model\n",
    "    :param pictures: Actual labeled images from the dataset\n",
    "    :return: The sum of the cross entropy loss function.\n",
    "    \"\"\"\n",
    "    losses = 0\n",
    "\n",
    "    for i, key in enumerate(outputs):\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        labelsTensor = pictures['class'].clone().detach()\n",
    "        losses += loss_func(outputs[key], labelsTensor.long().to(device))\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, device, lr_rate, epochs, train_loader):\n",
    "    \"\"\"\n",
    "    Method used by the model for training\n",
    "    :param model: The model to train\n",
    "    :param device: Which device to use for computation, GPU or CPU\n",
    "    :param lr_rate: The learning rate used by the optimizing function\n",
    "    :param epochs: How many epochs to train the model for\n",
    "    :param train_loader: The loader that provides the labeled images in batches\n",
    "    :return: An array containing the losses after each epoch\n",
    "    \"\"\"\n",
    "    num_epochs = epochs\n",
    "    losses = []\n",
    "    checkpoint_losses = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "    n_total_steps = len(train_loader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, pictures in enumerate(train_loader):\n",
    "            images = pictures['image'].to(device)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, pictures)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % (int(n_total_steps / 1)) == 0:\n",
    "                checkpoint_loss = torch.tensor(losses).mean().item()\n",
    "                checkpoint_losses.append(checkpoint_loss)\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{n_total_steps}], Loss: {checkpoint_loss:.4f}')\n",
    "\n",
    "    # Snippet used to save the models for inferring during runtime.\n",
    "    # model_save_path = r'D:\\COLLEGE_STUDIES\\SEM-6\\ML_NLP_project\\model\\house\\house_model_12.tar'\n",
    "    # torch.save({\n",
    "    #     'model_state_dict': model.state_dict(),\n",
    "    #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #     'loss': checkpoint_losses,\n",
    "    # }, model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "    return checkpoint_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [94/94], Loss: 0.8799\n",
      "Epoch [2/25], Step [94/94], Loss: 0.8277\n",
      "Epoch [3/25], Step [94/94], Loss: 0.7847\n",
      "Epoch [4/25], Step [94/94], Loss: 0.7413\n",
      "Epoch [5/25], Step [94/94], Loss: 0.7100\n",
      "Epoch [6/25], Step [94/94], Loss: 0.6808\n",
      "Epoch [7/25], Step [94/94], Loss: 0.6537\n",
      "Epoch [8/25], Step [94/94], Loss: 0.6384\n",
      "Epoch [9/25], Step [94/94], Loss: 0.6167\n",
      "Epoch [10/25], Step [94/94], Loss: 0.5994\n",
      "Epoch [11/25], Step [94/94], Loss: 0.5781\n",
      "Epoch [12/25], Step [94/94], Loss: 0.5613\n",
      "Epoch [13/25], Step [94/94], Loss: 0.5485\n",
      "Epoch [14/25], Step [94/94], Loss: 0.5382\n",
      "Epoch [15/25], Step [94/94], Loss: 0.5240\n",
      "Epoch [16/25], Step [94/94], Loss: 0.5095\n",
      "Epoch [17/25], Step [94/94], Loss: 0.4953\n",
      "Epoch [18/25], Step [94/94], Loss: 0.4822\n",
      "Epoch [19/25], Step [94/94], Loss: 0.4711\n",
      "Epoch [20/25], Step [94/94], Loss: 0.4591\n",
      "Epoch [21/25], Step [94/94], Loss: 0.4471\n",
      "Epoch [22/25], Step [94/94], Loss: 0.4374\n",
      "Epoch [23/25], Step [94/94], Loss: 0.4270\n",
      "Epoch [24/25], Step [94/94], Loss: 0.4162\n",
      "Epoch [25/25], Step [94/94], Loss: 0.4067\n"
     ]
    }
   ],
   "source": [
    "# Call the method to train the model\n",
    "checkpoint_losses = training(model, device, 0.0001, 25, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Validates the model after training.\n",
    "\n",
    "    :param model: The trained model.\n",
    "    :param dataloader: Dataloader providing labeled images in batches.\n",
    "    :param device: Device (CPU or GPU) for computation.\n",
    "    :return: Model accuracy in percentage.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pictures in dataloader:\n",
    "            images = pictures['image'].to(device)\n",
    "            labels = pictures['class'].to(device)\n",
    "\n",
    "            outputs = model(images)['class']  # Extract class predictions\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
    "\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            n_samples += labels.size(0)\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples if n_samples > 0 else 0.0  # Avoid division by zero\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "        \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Ensure correct device\n",
    "model.to(device)  # Move model to device\n",
    "\n",
    "# Call the validation function\n",
    "accuracy = validation(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
